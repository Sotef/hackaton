import cv2
import mediapipe as mp
import numpy as np
from collections import deque
from PIL import Image, ImageSequence
import time
import os

# ---------- –ù–∞—Å—Ç—Ä–æ–π–∫–∏ ----------
background_files = [
    r"D:\novosib_hack_t1_shabbat\hackaton\Shingeki-no-Kyojin-Anime-—Ñ—ç–Ω–¥–æ–º—ã-8027242.jpeg"
]
cap_index = 0            # –∏–Ω–¥–µ–∫—Å –∫–∞–º–µ—Ä—ã
mask_history_len = 5     # —É—Å—Ä–µ–¥–Ω–µ–Ω–∏–µ –ø–æ N –∫–∞–¥—Ä–∞–º
hard_thresh = 0.5        # –ø–æ—Ä–æ–≥ –¥–ª—è –±–∏–Ω–∞—Ä–∏–∑–∞—Ü–∏–∏
apply_clahe = True       # –∞–≤—Ç–æ —É–ª—É—á—à–µ–Ω–∏–µ –æ—Å–≤–µ—â—ë–Ω–Ω–æ—Å—Ç–∏
morph_kernel = (3,3)     # —è–¥—Ä–æ –¥–ª—è –º–æ—Ä—Ñ–æ–ª–æ–≥–∏–∏
draw_debug = True

# ------------------------------------------------------
mp_selfie_segmentation = mp.solutions.selfie_segmentation
segment = mp_selfie_segmentation.SelfieSegmentation(model_selection=1)

cap = cv2.VideoCapture(cap_index)
if not cap.isOpened():
    raise RuntimeError("–ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–∫—Ä—ã—Ç—å –∫–∞–º–µ—Ä—É")

# –ó–∞–≥—Ä—É–∑–∫–∞ —Ñ–æ–Ω–æ–≤ (–ø–æ–¥–¥–µ—Ä–∂–∫–∞ gif)
def load_bg(path):
    ext = os.path.splitext(path)[1].lower()
    if ext == ".gif":
        gif = Image.open(path)
        frames = [cv2.cvtColor(np.array(f.convert("RGB")), cv2.COLOR_RGB2BGR)
                  for f in ImageSequence.Iterator(gif)]
        return {"type":"gif", "frames": frames, "pos":0, "playing":True}
    else:
        img = cv2.imread(path)
        if img is None:
            # —Å–æ–∑–¥–∞—ë–º —Ü–≤–µ—Ç–Ω–æ–π —Ñ–æ–Ω, –µ—Å–ª–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω
            img = np.full((480,640,3), (50,50,50), dtype=np.uint8)
        return {"type":"img", "img": img}

bg_items = [load_bg(p) for p in background_files]
cur_bg = 0

mask_history = deque(maxlen=mask_history_len)
use_hard = False
invert_mode = False  # üîÅ False = –∑–∞–º–µ–Ω—è–µ–º —Ñ–æ–Ω, True = –∑–∞–º–µ–Ω—è–µ–º —á–µ–ª–æ–≤–µ–∫–∞

# CLAHE –¥–ª—è V-–∫–∞–Ω–∞–ª–∞
clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))

last_time = time.time()
frame_count = 0

print("Controls:")
print("  1/2/3 - –ø–µ—Ä–µ–∫–ª—é—á–∏—Ç—å —Ñ–æ–Ω")
print("  m - –∂–µ—Å—Ç–∫–∞—è/–º—è–≥–∫–∞—è –º–∞—Å–∫–∞")
print("  g - –ø–∞—É–∑–∞/–≤–æ—Å–ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏–µ gif")
print("  b - –≤–∫–ª—é—á–∏—Ç—å/–≤—ã–∫–ª—é—á–∏—Ç—å CLAHE")
print("  r - üîÅ –∏–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å —Ä–µ–∂–∏–º (—Ñ–æ–Ω ‚Üî —á–µ–ª–æ–≤–µ–∫)")
print("  q/Esc - –≤—ã–π—Ç–∏\n")

while True:
    ret, frame = cap.read()
    if not ret:
        break
    frame = cv2.flip(frame, 1)
    h, w = frame.shape[:2]

    # 1) –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ —É–ª—É—á—à–∞–µ–º –æ—Å–≤–µ—â—ë–Ω–Ω–æ—Å—Ç—å (CLAHE –Ω–∞ V)
    frame_proc = frame.copy()
    if apply_clahe:
        hsv = cv2.cvtColor(frame_proc, cv2.COLOR_BGR2HSV)
        v = hsv[:,:,2]
        v = clahe.apply(v)
        hsv[:,:,2] = v
        frame_proc = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)

    # 2) —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—è
    rgb = cv2.cvtColor(frame_proc, cv2.COLOR_BGR2RGB)
    result = segment.process(rgb)
    mask = result.segmentation_mask  # float32 [0..1]

    # 3) –º–æ—Ä—Ñ–æ–ª–æ–≥–∏—è (—É–±–∏—Ä–∞–µ–º —à—É–º)
    mask = cv2.erode(mask, np.ones(morph_kernel, np.uint8), iterations=1)
    mask = cv2.dilate(mask, np.ones((5,5), np.uint8), iterations=1)

    # 4) —Å–≥–ª–∞–∂–∏–≤–∞–Ω–∏–µ –ø–æ –≤—Ä–µ–º–µ–Ω–∏
    mask_history.append(mask)
    avg_mask = np.mean(mask_history, axis=0)

    # 5) –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –º–∞—Å–∫–∏
    if use_hard:
        m = (avg_mask > hard_thresh).astype(np.uint8)
        m = cv2.medianBlur(m, 5)
        m = np.expand_dims(m, axis=2)
    else:
        m = cv2.GaussianBlur(avg_mask, (15,15), 0)
        m = np.expand_dims(m, axis=2)
        m = np.clip(m, 0, 1)

    # 6) –≤—ã–±–∏—Ä–∞–µ–º —Ñ–æ–Ω (–∏–ª–∏ gif)
    bg_item = bg_items[cur_bg]
    if bg_item["type"] == "gif":
        frames = bg_item["frames"]
        idx = bg_item["pos"]
        bg_frame = frames[idx % len(frames)]
        if bg_item.get("playing", True):
            bg_item["pos"] = (bg_item["pos"] + 1) % len(frames)
    else:
        bg_frame = bg_item["img"]

    bg_resized = cv2.resize(bg_frame, (w, h))

    # 7) –∫–æ–º–±–∏–Ω–∏—Ä—É–µ–º
    if invert_mode:
        # üîÅ –†–ï–ñ–ò–ú "–∑–∞–º–µ–Ω—è–µ–º —á–µ–ª–æ–≤–µ–∫–∞" (—Ñ–æ–Ω –æ—Å—Ç–∞–≤–ª—è–µ–º)
        composed = (frame.astype(np.float32) * (1 - m) + bg_resized.astype(np.float32) * m).astype(np.uint8)
    else:
        # —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π —Ä–µ–∂–∏–º ‚Äî "–∑–∞–º–µ–Ω—è–µ–º —Ñ–æ–Ω"
        composed = (frame.astype(np.float32) * m + bg_resized.astype(np.float32) * (1 - m)).astype(np.uint8)

    # 8) –æ—Ç—Ä–∏—Å–æ–≤–∫–∞ UI
    if draw_debug:
        frame_count += 1
        now = time.time()
        fps_text = ""
        if now - last_time >= 1.0:
            fps = frame_count / (now - last_time)
            last_time = now
            frame_count = 0
            fps_text = f"FPS: {fps:.1f}"

        info = f"{'HARD' if use_hard else 'SOFT'} | CLAHE:{'ON' if apply_clahe else 'OFF'} | bg:{cur_bg+1}/{len(bg_items)} | {'INVERT' if invert_mode else 'NORMAL'} {fps_text}"
        cv2.putText(composed, info, (10,25), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255,255,255), 2, cv2.LINE_AA)

    cv2.imshow("Enhanced Background Replacement", composed)

    # 9) –∫–ª–∞–≤–∏—à–∏ —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è
    key = cv2.waitKey(30) & 0xFF
    if key in (27, ord('q')):  # Esc / q
        break
    elif key in (ord('1'), ord('2'), ord('3')):
        idx = int(chr(key)) - 1
        if 0 <= idx < len(bg_items):
            cur_bg = idx
    elif key == ord('m'):
        use_hard = not use_hard
    elif key == ord('g'):
        if bg_items[cur_bg]["type"] == "gif":
            bg_items[cur_bg]["playing"] = not bg_items[cur_bg].get("playing", True)
    elif key == ord('b'):
        apply_clahe = not apply_clahe
    elif key == ord('r'):
        invert_mode = not invert_mode
        print(f"–†–µ–∂–∏–º –ø–µ—Ä–µ–∫–ª—é—á—ë–Ω: {'–∑–∞–º–µ–Ω—è–µ–º —á–µ–ª–æ–≤–µ–∫–∞' if invert_mode else '–∑–∞–º–µ–Ω—è–µ–º —Ñ–æ–Ω'}")

cap.release()
cv2.destroyAllWindows()
